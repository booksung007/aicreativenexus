2024.05.02
On the assumtion that you have a graphic card(some budet computers don't have gpu) here is how you can check your graphic card. 

following is the table for models out for sale and how much VRAM they have. Do keep in mind VRAM is not the only bottle neck in running the AI locally you also need sufficent amount of memory and cpu to smothly run the AI. 

How to check your VRAM 

//draft1
2024.05.12
I won't bore you with deep technical stuff. A because its boring and B I don't know deeply into this subject neither. I am also the the same end user just like you. However, I would like to share some things I figured out while installing local AI models. 

From what I understand local AI mostly use VRAM, certain type of RAM tied with the GPU. This is mostly used by the AI to 
So you have to check how many VRAM your GPU have in order to figure out what kind of model you can run. 

Mostly CPU MEMORY gpu is needed to run the model. fuck I don't thing I know enough to write about this. I don't know what cpu and ram is needed for doing this. I don't think this is good post to make. 










source: https://rentry.org/cixpvn93