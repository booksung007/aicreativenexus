//draft3 gemini
In this guide, I'll walk you through setting up a local LLM model using oobabooga text-generation-webui. LLM models, or Large Language Models, are powerful AI systems capable of generating text, translating languages, and writing different kinds of creative content. oobabooga offers a user-friendly interface for running these models on my own computer.

**Choosing a Backend Program:**

The backend program runs the LLM model on the computer. Several options exist, each with its own strengths. I'll be focusing on oobabooga in this guide due to its simplicity and ease of use.

**Source:**

- [Fireship](URL youtube channel fireship ON youtube.com)
- https://www.youtube.com/watch?v=XwL_cRuXM2E&ab_channel=bycloud


**Picking an oobabooga Alternative (Optional):**

While oobabooga offers a great starting point, other backend programs provide more specific feature like fine-tuning LLM models. I may explore these options in the future.

**Why oobabooga?**

I chose oobabooga for its clear and minimalistic interface, making it easy to use for beginners. Additionally, its well-rounded options felt user-friendly.

Source: 
https://www.youtube.com/watch?v=C-7jGYOGvy4&t=479s&ab_channel=Aitrepreneur

**Setting Up oobabooga Text-Generation-Webui:**

1. Downloaded Git for Windows to copy the oobabooga repository. You can find Git at [https://git-scm.com/downloads](https://git-scm.com/downloads).
    
2. Headed to the oobabooga webpage on Github and clicked the green "<> Code" button in the top right corner.
    
3. A small window appeared. Copie the HTTPS link shown there.
    
4. Created a new folder on the desktop to store the oobabooga program. Avoided using spaces in the folder name, as this can cause issues.
    

**Note:** If English isn't your primary language and your using Windows, Consider creating the folder and associated rout to the folder with only English characters in the name. This can prevent errors during installation.

5. I opened the Command Prompt (CMD) in my new folder. I did this by clicking on the folder tab and typing "CMD" in the address bar.
    
6. I typed the following command and pressed Enter:
    

```
git clone https://github.com/oobabooga/text-generation-webui.git
```

Simply paste the link you copied earlier.

7. This cloned the oobabooga repository. Navigated into the newly created folder.
    
8. Located the "start_windows.bat" file and double-clicked it (for Windows users).
    
9. This downloaded the necessary files to complete the installation.
    
10. During installation, the program asked me to select the GPU I'm using. Chose the correct option for your computer or selected "None" if you didn't have one.
    

**Not sure about my hardware specifications?** Check out this post for guidance (link to be added).

11. The program then asked if you have a very old GPU. In most cases, the answer would be "no."
    
12. Once installation is complete, the program displayed a local URL to launch the oobabooga program. Copie and pasted this URL into my web browser.
    

**Important:** To keep the program running, You shouldn't close the "start_windows.bat" file. You can close the browser window, but the main program runs through the bat file.

**Congratulations!** You've successfully installed oobabooga. Now, let's move on to loading the LLM model.

**This guide is a work in progress. Stay tuned for the following sections:**

- How to Load an LLM Model from Hugging Face
- Using a Frontend Program (Optional)
- Loading a Character Card

//draft2
2024.05.12
The backend is the program that will run the LLM model on to your computer. Depending on the program can help you with finetuning LLM models, helping you check if your hardware can run the LLM models and provide you with different options engaging with the LLM models. 
I checked youtube for candidates and got some recommendation.
source: 
https://www.youtube.com/watch?v=GyllRd2E6fg&ab_channel=Fireship  
https://www.youtube.com/watch?v=XwL_cRuXM2E&ab_channel=bycloud

1. oobabooga text-generation-webui
2. ollama
3. axolotl
4. LM studio

Looking over them I choose to go with 'oobabooga'. Other backend programs look cool and provide professional options for tweeking LLM models but at the same time all the excessive options look daunting. While 'oobabooga' seem to have a simple and minimalistic look that I find comfortable to look at and it's options seem well rounded and easy to use. Also I  like the name 'oobabooga'. I being the tech caveman that I am stumbling around the AI technology jungle made the name 'oobabooga' somewhat relateable. . In the future I may try out different AI backend program but as of now I will stick with 'oobabooga'.

I will go over how I set up the 'oobabooga text-generation-webui' on my computer and look at how I ran my first model I picked from the preveous post. To check how I pick the local model for myself check this post over here.

[[04. Understanding LLM in Huggingface.com]]

Ok, let start with installation. I followed the youtube tutorial given by 'Aitrepreneur'.
source: 
https://www.youtube.com/watch?v=C-7jGYOGvy4&t=479s&ab_channel=Aitrepreneur
1. Download git for windows. This will allow you to copy the repositary.
	1. Link for git: https://git-scm.com/
2. Go to the 'Github' page for 'oobabooga' web page and click the green '<>code' button on the top right of the page. 
3. Pressing this will open a small window, copy the HTTPS link.
4. Go in to you desktop and make a folder. This is the folder you will put teh 'oobabooga' program.
	1. Be aware, avoid putting space in the file name for this might cause issue. 
	2. Also if you are using windows and english is not your first language, I suggest you make this file where all the file name is english. I faced with an error on my first install and had to change the file location.(I made the file in C:drive.)
5. Click on the folder tab and put in CMD on the tab. This will open up the CMD window with the path to your folder already accessed. 
6. Type in: >git clone https://github.com/oobabooga/text-generation-webui.git
	1. You can just paste the address.
7. This will clone the repositary. Go in to the newly made folder.
8. Go in to this folder and look for the 'start_windows.bat' file and click it.(For window users) 
9. This will download the file to complete the installation. 
10. Before the installation is complete the program will ask what kind of GPU you are using. Pick the correct GPU or none if you don't have none then enter. 
	1. Not sure what your hardware specification is? Check this post to find out.(underconstruction) 
11. Then it will ask you if you have a very old GPU. In most case tihs will be a 'no'.
12. The instalation will be complete and the program will give you a local URL to start your 'oobabooga' program. Copy paste this URL into your browser of choice.
	1. Be aware, if you want to keep the program running don't close the 'start_windows.bat' file. You can close the browser window but the main program is actually the bat file. 

The installation process is compleate! Now lets put the LLM model in to the right folder.

If you haven't choosen your local LLM model check this post to find the model you want to try out.
[[04. Understanding LLM in Huggingface.com]]

1. Go to the site 'huggingface.co'.
2. Click the local LLM model you want to download.  
3. Copy the name of the model. 
4. Open up the 'oobabooga text generation ui' 
5. Open the tab 'Model'
6. On the right side of the page there is a box titled 'Download model or LoRa'. Paste the model name you copied and click the orange 'Download' button below
7. The model will be downloaded from the 'huggingface.co' to your system. You can check the process in the cmd window.
8. After the process is completed on the same page click the blue refresh button on the right and push the drop down menu and you will see the model you downloaded.
9. The 'oobaboga text generator' will automatically set up how to the model should be loaded.

Thats how I succesfully ran a local LLM model on my system. Now there is just one more step before actually writing or roleplaying. Loading a character card. 

How to load a character card on my 'oobabooga text generator'?(underconstruction)

Or you can install a frontend program before continuing on with loading the character card.(underconsturction) 

[[07. Frontend what is it and what does it do]](underconstruction)

//draft1 
2024.05.12
The backend is the program that will run the LLM model on to your computer. The program can run the local LLM file downloaded on to your computer. 

I checked youtube for candidates and got some recommendation.(source below) 

1. oobabooga text-generation-webui
2. ollama
3. axolotl
4. LM studio

Looking over them I choose to go with 'oobabooga'. Other backend programs looks cool and very professional providing with many options for tweeking. But at the same time they look daunting. Also I kind of like the name 'oobabooga' it some what relate to the name. I being the tech caveman that I am going through the jungle of AI technology stubling around like a caveman the name is really relatable. Also 'oobabooga' backend program seem like a well rounded program. After I get used to all these AI things I will try other programs but for now I will stick with one program.

In this post I will go over how I set up the 'oobabooga text-generation-webui' on my computer and look at how to install and run my first model I picked from the preveous post. 

To check how to pick the local model for you check this post over here.

Ok, let start with installation. 
1. Download git for windows. This will allow you to copy the repositary.
	1. Link for git: 
2. Go to the 'Github' page for 'oobabooga' web page and click the green '<>code' button on the top right of the page. 
3. Pressing this will open a small window, copy the HTTPS link.
4. Go in to you desktop and make a folder. This is the folder you will put teh 'oobabooga' program.
	1. Be aware, avoid putting space in the file name for this might cause issue. 
	2. Also if you are using windows and english is not your first language, I suggest you make this file where all the file name is english. I faced with an error on my first install and had to change the file location.(I made the file in C:drive.)
5. Click on the folder tab and put in CMD on the tab. This will open up the CMD window with the path to your folder already accessed. 
6. Type in: >git clone https://github.com/oobabooga/text-generation-webui.git
	1. You can just paste the address.
7. This will clone the repositary. Go in to the newly made folder.
8. Go in to this folder and look for the 'start_windows.bat' file and click it.(For window users) 
9. This will download the file to compleat the instalation. 
10. Before the instalation is compleate the program will ask what kind of GPU you are using. Pick the correct GPU or none if you don't have none then enter. 
	1. Not sure what your hardware specification is? Check this post to find out. 
11. Then it will ask you if you have a very old GPU. In most case tihs will be a 'no'.
12. The instalation will be compleat and the program will give you a local URL to start your 'oobabooga' program. Copy paste this URL into your browser of choice.
	1. Be aware, if you want to keep the program running don't close the 'start_windows.bat' file. You can close the browser window but the main program is actually the bat file. 

The instalation process is compleate! Now lets put the LLM model in to the right folder.

If you haven't choosen your local LLM model check this post to find the model you want to try out.
[[04. Understanding LLM in Huggingface.com]]


1. Go to the site 'huggingface.co'.
2. Click the local LLM model you want to download.  
3. Copy the name of the model. 
4. Open up the 'oobabooga text generation ui' 
5. Open the tab 'Model'
6. On the right side of the page there is a box titled 'Download model or LoRa'. Paste the model name you copied and click the orange 'Download' button below
7. The model will be downloaded from the 'huggingface.co' to your system. You can check the process in the cmd window.
8. After the process is completed on the same page click the blue refreash button on the right and push the drop down menu and you will see the model you downloaded.
9. The 'oobaboga text generator' will automatically set up how to the model should be loaded.

Thats it! I have succesfully installed a local LLM model on my system. Now there is just one more step before actually writing or roleplaying. Loading a character card. 

How to load a character card on my 'oobabooga text generator'?

Or you can install a frontend program before continuing on with loading the character card. 

[[07. Frontend what is it and what does it do]]

Referance Youtube video: 
https://www.youtube.com/watch?v=GyllRd2E6fg&ab_channel=Fireship
https://www.youtube.com/watch?v=C-7jGYOGvy4&t=479s&ab_channel=Aitrepreneur
https://www.youtube.com/watch?v=XwL_cRuXM2E&ab_channel=bycloud